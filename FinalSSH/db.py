"""
db.py — SQLite data layer
=========================
Tables
------
  users            : tracks each user's current difficulty state
  questions        : question bank (Groq-generated questions are persisted here)
  interaction_logs : raw submission payloads + computed ΔD for audit/ML
"""

import json
import os
import sqlite3

DB_PATH = os.path.join(os.path.dirname(__file__), "study_assistant.db")

# ─────────────────────────────────────────────────────────────────────────────
# Schema (DDL)
# ─────────────────────────────────────────────────────────────────────────────

SCHEMA = """
-- ── Users ──────────────────────────────────────────────────────────────────
CREATE TABLE IF NOT EXISTS users (
    user_id             TEXT    PRIMARY KEY,
    current_difficulty  REAL    NOT NULL DEFAULT 5.0,
    questions_answered  INTEGER NOT NULL DEFAULT 0,
    created_at          TEXT    NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at          TEXT    NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- ── Question Bank ───────────────────────────────────────────────────────────
-- Stores questions generated by Groq (or manually seeded).
-- `options` is JSON: {"A": "...", "B": "...", "C": "...", "D": "..."}
CREATE TABLE IF NOT EXISTS questions (
    question_id     TEXT    PRIMARY KEY,
    topic           TEXT    NOT NULL,
    question_text   TEXT    NOT NULL,
    options         TEXT    NOT NULL,   -- JSON blob
    correct_answer  TEXT    NOT NULL,   -- "A" | "B" | "C" | "D"
    difficulty      REAL    NOT NULL,   -- 0.0 – 10.0
    expected_time_ms INTEGER NOT NULL DEFAULT 25000,
    created_at      TEXT    NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_questions_difficulty ON questions(difficulty);
CREATE INDEX IF NOT EXISTS idx_questions_topic      ON questions(topic);

-- ── Interaction Logs ────────────────────────────────────────────────────────
-- Raw submission payload + computed values, useful for ML/analytics.
CREATE TABLE IF NOT EXISTS interaction_logs (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id         TEXT    NOT NULL,
    question_id     TEXT    NOT NULL,
    payload         TEXT    NOT NULL,   -- full JSON from frontend
    delta_d         REAL,               -- computed ΔD
    new_difficulty  REAL,               -- D_{n+1}
    logged_at       TEXT    NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id)     REFERENCES users(user_id),
    FOREIGN KEY (question_id) REFERENCES questions(question_id)
);

CREATE INDEX IF NOT EXISTS idx_logs_user     ON interaction_logs(user_id);
CREATE INDEX IF NOT EXISTS idx_logs_question ON interaction_logs(question_id);
"""


# ─────────────────────────────────────────────────────────────────────────────
# Connection
# ─────────────────────────────────────────────────────────────────────────────

def _get_conn() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    conn.execute("PRAGMA journal_mode=WAL")   # safe for concurrent reads
    conn.execute("PRAGMA foreign_keys=ON")
    return conn


def init_db() -> None:
    """Create tables if they don't exist. Safe to call on every startup."""
    with _get_conn() as conn:
        conn.executescript(SCHEMA)


# ─────────────────────────────────────────────────────────────────────────────
# User helpers
# ─────────────────────────────────────────────────────────────────────────────

def get_or_create_user(user_id: str, initial_difficulty: float = 5.0) -> float:
    """
    Returns the user's current_difficulty.
    Creates a new user row with `initial_difficulty` if they don't exist.
    """
    with _get_conn() as conn:
        row = conn.execute(
            "SELECT current_difficulty FROM users WHERE user_id = ?",
            (user_id,)
        ).fetchone()
        if row:
            return float(row["current_difficulty"])
        conn.execute(
            "INSERT INTO users (user_id, current_difficulty) VALUES (?, ?)",
            (user_id, initial_difficulty),
        )
        return initial_difficulty


def update_user_difficulty(user_id: str, new_difficulty: float) -> None:
    """Upsert the user's difficulty and increment their question counter."""
    with _get_conn() as conn:
        conn.execute("""
            INSERT INTO users (user_id, current_difficulty, questions_answered, updated_at)
            VALUES (?, ?, 1, CURRENT_TIMESTAMP)
            ON CONFLICT(user_id) DO UPDATE SET
                current_difficulty  = excluded.current_difficulty,
                questions_answered  = questions_answered + 1,
                updated_at          = CURRENT_TIMESTAMP
        """, (user_id, new_difficulty))


# ─────────────────────────────────────────────────────────────────────────────
# Question helpers
# ─────────────────────────────────────────────────────────────────────────────

def save_question(
    question_id: str,
    topic: str,
    q: dict,
    difficulty: float,
    expected_time_ms: int,
) -> None:
    """
    Persist a Groq-generated question.
    Silently ignores duplicate question_ids (INSERT OR IGNORE).
    """
    with _get_conn() as conn:
        conn.execute("""
            INSERT OR IGNORE INTO questions
                (question_id, topic, question_text, options, correct_answer,
                 difficulty, expected_time_ms)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            question_id,
            topic,
            q["question"],
            json.dumps(q["options"]),
            q["correct"],
            difficulty,
            expected_time_ms,
        ))


def get_question(question_id: str) -> dict | None:
    """Return a question row as a plain dict, or None if not found."""
    with _get_conn() as conn:
        row = conn.execute(
            "SELECT * FROM questions WHERE question_id = ?",
            (question_id,)
        ).fetchone()
        if not row:
            return None
        d = dict(row)
        d["options"] = json.loads(d["options"])
        return d


def get_nearest_question(
    target_difficulty: float,
    exclude_id: str,
    topic: str | None = None,
) -> dict | None:
    """
    Find the stored question whose difficulty is closest to target_difficulty,
    excluding the question the user just answered.
    Optionally filters by topic.
    """
    with _get_conn() as conn:
        if topic:
            row = conn.execute("""
                SELECT * FROM questions
                WHERE question_id != ?
                  AND topic = ?
                ORDER BY ABS(difficulty - ?) ASC
                LIMIT 1
            """, (exclude_id, topic, target_difficulty)).fetchone()
        else:
            row = conn.execute("""
                SELECT * FROM questions
                WHERE question_id != ?
                ORDER BY ABS(difficulty - ?) ASC
                LIMIT 1
            """, (exclude_id, target_difficulty)).fetchone()

        if not row:
            return None
        d = dict(row)
        d["options"] = json.loads(d["options"])
        return d


# ─────────────────────────────────────────────────────────────────────────────
# Interaction log
# ─────────────────────────────────────────────────────────────────────────────

def log_interaction(
    user_id: str,
    question_id: str,
    payload: dict,
    delta_d: float,
    new_difficulty: float,
) -> None:
    """Append one submission record to interaction_logs."""
    with _get_conn() as conn:
        conn.execute("""
            INSERT INTO interaction_logs
                (user_id, question_id, payload, delta_d, new_difficulty)
            VALUES (?, ?, ?, ?, ?)
        """, (user_id, question_id, json.dumps(payload), delta_d, new_difficulty))
